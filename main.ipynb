{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38847859-a52a-4b4f-8f11-dcaab9d46835",
   "metadata": {},
   "source": [
    "# 神经网络框架调研：PyTorch、TensorFlow、JAX\n",
    "\n",
    "![nn](https://github.com/user-attachments/assets/73398021-d465-4c76-ba10-380fe353c8b9)\n",
    "\n",
    "> 从安装到数组运算、自动微分、网络搭建等多个方面，分析 PyTorch、TensorFlow、JAX 这三个神经网络框架的特色和优劣。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9d465a-433c-4cfd-85e1-3c1043fe70e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T08:25:57.879447Z",
     "iopub.status.busy": "2024-12-22T08:25:57.878296Z",
     "iopub.status.idle": "2024-12-22T08:25:58.068798Z",
     "shell.execute_reply": "2024-12-22T08:25:58.068408Z",
     "shell.execute_reply.started": "2024-12-22T08:25:57.879382Z"
    }
   },
   "source": [
    "## 概览\n",
    "\n",
    "在目前的神经网络领域，主流的框架基本就是 Facebook 的 PyTorch，Google 的 TensorFlow、JAX 这三个。其他的框架已经停止更新的 Theano，或者一些小众的框架比如 Amazon 的 MXNet，百度的 PaddlePaddle，华为的 MindSpore 等等，基本就是在他们公司内部及相关联的生态中使用，故在此不做过多介绍。\n",
    "\n",
    "**PyTorch** 由 Facebook AI Research Lab (FAIR) 于 2016 年发布，强调易用性和灵活性，广泛应用于学术实验和模型原型设计，已经逐渐成为科研界和业界流行的深度学习框架。\n",
    "\n",
    "**TensorFlow** 由 Google Brain 团队开发，于 2015 年开源。不过众所周知，TensorFlow 1.0 的静态图 API 相当反人类，所以 2019 年 TensorFlow 2.0 版本的发布算是它的新生。\n",
    "\n",
    "**JAX** 由 Google 于 2018 年推出，具有与 NumPy 高度相似的 API，以及极高的灵活性和强大的自动微分功能。它的底层和 TensorFlow 一样使用了 XLA (Accelerated Linear Algebra)。近年来，JAX 在深度学习领域，尤其是在涉及到大量数学计算的问题上，受到越来越多关注。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7011be45-9e6e-4a71-b0ff-4a1da6055b13",
   "metadata": {},
   "source": [
    "## 框架的安装\n",
    "\n",
    "在配置好 CUDA 环境或者仅考虑 CPU 版本的情况下，这三个框架的安装都已经做到了足够的简单。这里简单做一个概述，但建议在实际安装的时候参考官网给出的说明。\n",
    "\n",
    "### PyTorch\n",
    "\n",
    "PyTorch 的安装参考 https://pytorch.org/get-started/locally/, 需要注意的一点是 CPU 版本需要指定 PyTorch 自己的网址。\n",
    "\n",
    "```sh\n",
    "pip3 install torch --index-url https://download.pytorch.org/whl/cpu  # CPU\n",
    "pip3 install torch  # GPU\n",
    "```\n",
    "\n",
    "其 CPU 版本的安装包大小约 170 MB。\n",
    "\n",
    "### TensorFlow\n",
    "\n",
    "TensorFlow 的安装参考官网，需要使用合适的方式访问 https://www.tensorflow.org/install/pip\n",
    "\n",
    "```sh\n",
    "pip install tensorflow_cpu  # CPU\n",
    "pip install 'tensorflow[and-cuda]'  # GPU\n",
    "```\n",
    "\n",
    "其 CPU 版本的安装包大小约 220 MB。\n",
    "\n",
    "### JAX\n",
    "\n",
    "```sh\n",
    "pip install jax  # CPU\n",
    "pip install \"jax[cuda12]\"  # GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b52d30f-71a3-44ae-8cf1-81de2efa9a71",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9239e411-5173-4545-a167-6770ddaa32aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:18.676098Z",
     "iopub.status.busy": "2024-12-22T10:43:18.675881Z",
     "iopub.status.idle": "2024-12-22T10:43:19.622041Z",
     "shell.execute_reply": "2024-12-22T10:43:19.621473Z",
     "shell.execute_reply.started": "2024-12-22T10:43:18.676085Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b80d6a8-e671-42ae-be72-1e422bb5f0c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:17.132176Z",
     "iopub.status.busy": "2024-12-22T10:43:17.131869Z",
     "iopub.status.idle": "2024-12-22T10:43:18.675433Z",
     "shell.execute_reply": "2024-12-22T10:43:18.674780Z",
     "shell.execute_reply.started": "2024-12-22T10:43:17.132142Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-22 18:43:17.249068: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-22 18:43:17.277059: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5accab0-c526-450c-a517-2aa05598cd1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:19.622595Z",
     "iopub.status.busy": "2024-12-22T10:43:19.622463Z",
     "iopub.status.idle": "2024-12-22T10:43:19.625160Z",
     "shell.execute_reply": "2024-12-22T10:43:19.624837Z",
     "shell.execute_reply.started": "2024-12-22T10:43:19.622582Z"
    }
   },
   "outputs": [],
   "source": [
    "from jax import numpy as jnp\n",
    "import jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd17f0-eed6-4913-a56d-b3c598fd14ba",
   "metadata": {},
   "source": [
    "## 功能和 API 对比\n",
    "\n",
    "一个神经网络框架最基础的功能莫过于在 CPU 或 GPU 上进行多维矩阵运算和自动微分了。利用这两个功能可以手搓一个神经网络，但为了易用性，神经网络框架往往还内置了一些常用的网络结构，包括全连接层、卷积层等等。除此之外，监督式学习往往还涉及到了数据的预处理，最好有一些函数能够方便地读取数据、给数据分组。接下来，我们就从这些方面来看看这三个框架。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a87bb3-0c47-457b-933f-8704efeaeb88",
   "metadata": {},
   "source": [
    "### 数组运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe415f4-ba4d-450e-9108-d01ba3554cd0",
   "metadata": {},
   "source": [
    "#### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8310516f-ad82-4d00-a97e-df61d6268ba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:19.625538Z",
     "iopub.status.busy": "2024-12-22T10:43:19.625430Z",
     "iopub.status.idle": "2024-12-22T10:43:19.675084Z",
     "shell.execute_reply": "2024-12-22T10:43:19.674415Z",
     "shell.execute_reply.started": "2024-12-22T10:43:19.625528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19, 22],\n",
       "        [43, 50]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "c = torch.matmul(a, b)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1706b-13c4-46f5-b388-92476c762535",
   "metadata": {},
   "source": [
    "- 数组操作和 NumPy 有一些不同。比如，你应该使用 `torch.svd` 而非 `torch.linalg.svd`\n",
    "- 数组类型不全是自动转换的，你依然需要确保数组被初始化为合适的类型（如 `float32` 而非 `int`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "842ac769-bf06-4eaa-aa66-10d2d315bc6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:19.676559Z",
     "iopub.status.busy": "2024-12-22T10:43:19.675926Z",
     "iopub.status.idle": "2024-12-22T10:43:19.697778Z",
     "shell.execute_reply": "2024-12-22T10:43:19.696653Z",
     "shell.execute_reply.started": "2024-12-22T10:43:19.676515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.9444, 3.0910],\n",
       "        [3.7612, 3.9120]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "770be445-9532-40f1-820c-6bff5a1dc0b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:19.700930Z",
     "iopub.status.busy": "2024-12-22T10:43:19.700464Z",
     "iopub.status.idle": "2024-12-22T10:43:19.728544Z",
     "shell.execute_reply": "2024-12-22T10:43:19.727561Z",
     "shell.execute_reply.started": "2024-12-22T10:43:19.700883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.svd(\n",
       "U=tensor([[-0.4033, -0.9150],\n",
       "        [-0.9150,  0.4033]]),\n",
       "S=tensor([7.2069e+01, 5.5507e-02]),\n",
       "V=tensor([[-0.6523, -0.7580],\n",
       "        [-0.7580,  0.6523]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.svd(c.to(torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf0086-eb40-40ca-a9e6-248d2b151195",
   "metadata": {},
   "source": [
    "#### TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "424ad181-cdd8-4c88-9b22-e19ebdc58fed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:19.729781Z",
     "iopub.status.busy": "2024-12-22T10:43:19.729484Z",
     "iopub.status.idle": "2024-12-22T10:43:19.790282Z",
     "shell.execute_reply": "2024-12-22T10:43:19.789826Z",
     "shell.execute_reply.started": "2024-12-22T10:43:19.729753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[19, 22],\n",
       "       [43, 50]], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1, 2], [3, 4]])\n",
    "b = tf.constant([[5, 6], [7, 8]])\n",
    "c = tf.matmul(a, b)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bba680-04e2-48a0-b18b-9cddb1662da7",
   "metadata": {},
   "source": [
    "- 数组操作和 NumPy 有一些不同。比如，你应该使用 `tf.math.log` 而非 `tf.log`\n",
    "- 数组类型需要手动转换，你需要确保数组被初始化为合适的类型（如 `float32` 而非 `int`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffdda830-fa07-44e2-8db7-d50e75438162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:19.791034Z",
     "iopub.status.busy": "2024-12-22T10:43:19.790838Z",
     "iopub.status.idle": "2024-12-22T10:43:19.821503Z",
     "shell.execute_reply": "2024-12-22T10:43:19.820566Z",
     "shell.execute_reply.started": "2024-12-22T10:43:19.791016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2.944439 , 3.0910425],\n",
       "       [3.7612002, 3.912023 ]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(tf.cast(c, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0fd3dbf-0e68-42e6-b303-ca5db872d702",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:19.822735Z",
     "iopub.status.busy": "2024-12-22T10:43:19.822402Z",
     "iopub.status.idle": "2024-12-22T10:43:19.844673Z",
     "shell.execute_reply": "2024-12-22T10:43:19.844051Z",
     "shell.execute_reply.started": "2024-12-22T10:43:19.822708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([7.206939e+01, 5.550127e-02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 0.40334514,  0.9150479 ],\n",
       "        [ 0.9150479 , -0.40334514]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 0.6522966 ,  0.75796384],\n",
       "        [ 0.75796384, -0.6522966 ]], dtype=float32)>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.svd(tf.cast(c, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a8f46d-94cb-4268-a717-99275d806493",
   "metadata": {},
   "source": [
    "#### JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4495e4f-bd38-41d7-84a0-316faa32dc49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:19.845692Z",
     "iopub.status.busy": "2024-12-22T10:43:19.845427Z",
     "iopub.status.idle": "2024-12-22T10:43:19.925570Z",
     "shell.execute_reply": "2024-12-22T10:43:19.925285Z",
     "shell.execute_reply.started": "2024-12-22T10:43:19.845668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[19, 22],\n",
       "       [43, 50]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = jnp.array([[1, 2], [3, 4]])\n",
    "b = jnp.array([[5, 6], [7, 8]])\n",
    "c = jnp.matmul(a, b)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85fc653-f97d-4afa-9560-8daf423701a8",
   "metadata": {},
   "source": [
    "- 数组操作和 NumPy 几乎一致，除了一点[细微的差别](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#in-place-updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42bc8360-b652-4578-8144-3d5ea00b641b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:19.926057Z",
     "iopub.status.busy": "2024-12-22T10:43:19.925929Z",
     "iopub.status.idle": "2024-12-22T10:43:19.940518Z",
     "shell.execute_reply": "2024-12-22T10:43:19.940175Z",
     "shell.execute_reply.started": "2024-12-22T10:43:19.926046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[2.944439 , 3.0910425],\n",
       "       [3.7612002, 3.912023 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.log(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebe67757-84a4-4dc6-bf55-da6b18fd64b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:19.940978Z",
     "iopub.status.busy": "2024-12-22T10:43:19.940862Z",
     "iopub.status.idle": "2024-12-22T10:43:19.990911Z",
     "shell.execute_reply": "2024-12-22T10:43:19.990159Z",
     "shell.execute_reply.started": "2024-12-22T10:43:19.940967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVDResult(U=Array([[-0.40334493, -0.915048  ],\n",
       "       [-0.91504794,  0.40334517]], dtype=float32), S=Array([7.206938e+01, 5.550685e-02], dtype=float32), Vh=Array([[-0.6522967, -0.7579638],\n",
       "       [-0.7579638,  0.6522967]], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.linalg.svd(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961bc7dc-6b74-4d1d-ae9c-dae59c835c19",
   "metadata": {},
   "source": [
    "### 自动微分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4e9d7b-9662-4772-a5a3-b9a0721ab6c5",
   "metadata": {},
   "source": [
    "#### PyTorch\n",
    "\n",
    "只需要对输出做 `backward`， 就能得到它对输入的导数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ade3d99-ef3f-4112-a290-4809c6e9e341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:19.991692Z",
     "iopub.status.busy": "2024-12-22T10:43:19.991477Z",
     "iopub.status.idle": "2024-12-22T10:43:20.003754Z",
     "shell.execute_reply": "2024-12-22T10:43:20.002388Z",
     "shell.execute_reply.started": "2024-12-22T10:43:19.991670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = x**2\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba40117c-50ab-4403-a12b-3da9e5291e2c",
   "metadata": {},
   "source": [
    "#### TensorFlow\n",
    "可以对 `GradientTape` 这一上下文中进行的操作做微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ce5628c-17be-4f18-b0e3-5c0666dd177a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:20.005513Z",
     "iopub.status.busy": "2024-12-22T10:43:20.005165Z",
     "iopub.status.idle": "2024-12-22T10:43:20.057270Z",
     "shell.execute_reply": "2024-12-22T10:43:20.056730Z",
     "shell.execute_reply.started": "2024-12-22T10:43:20.005480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x**2\n",
    "tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e6b5fe-b696-4b6a-9f6a-c6948d7b0664",
   "metadata": {},
   "source": [
    "#### JAX\n",
    "\n",
    "JAX 更加函数化。你需要通过 `jax.grad` 得到函数 $f$ 的导函数 $f'$，再计算导函数 $f'(x)$ 即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f3dda2b-b80d-4207-ac93-6d469d9c5ba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:20.057979Z",
     "iopub.status.busy": "2024-12-22T10:43:20.057814Z",
     "iopub.status.idle": "2024-12-22T10:43:20.129337Z",
     "shell.execute_reply": "2024-12-22T10:43:20.128880Z",
     "shell.execute_reply.started": "2024-12-22T10:43:20.057964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(6., dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss_fn(x):\n",
    "    return x**2\n",
    "grad_fn = jax.grad(loss_fn)\n",
    "grad_fn(3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcbfc64-628d-417a-b2f3-84110ffe529b",
   "metadata": {},
   "source": [
    "JAX 还支持更加灵活的导数，包括高阶导数、Hessian 矩阵，Jacobian-vector 乘积（`jax.jvp`，前向传播）和 vector-Jacobian 乘积（`jax.vjp`，反向传播）等等，在此不一一列举，感兴趣可查阅 [JAX Autodiff Cookbook](https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a5ada5-5b5a-443d-b90f-745e14955035",
   "metadata": {},
   "source": [
    "### 常用网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8823db-482c-4fa5-a2b4-7b6b18c846af",
   "metadata": {},
   "source": [
    "#### PyTorch\n",
    "\n",
    "`torch.nn` 模块内置各类层和神经网络组件。指定每一层的输入输出维度和激活函数即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f9211a2-e154-4bea-810e-da16bc3cbd78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:20.129988Z",
     "iopub.status.busy": "2024-12-22T10:43:20.129855Z",
     "iopub.status.idle": "2024-12-22T10:43:20.134459Z",
     "shell.execute_reply": "2024-12-22T10:43:20.134060Z",
     "shell.execute_reply.started": "2024-12-22T10:43:20.129976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (3): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(64, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10),\n",
    "    nn.Softmax(dim=-1)\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "232dde59-72db-4ca8-85c0-4d93699fe8d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:20.134984Z",
     "iopub.status.busy": "2024-12-22T10:43:20.134850Z",
     "iopub.status.idle": "2024-12-22T10:43:20.164862Z",
     "shell.execute_reply": "2024-12-22T10:43:20.164038Z",
     "shell.execute_reply.started": "2024-12-22T10:43:20.134971Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1130, 0.1304, 0.0751, 0.0859, 0.0861, 0.0781, 0.0827, 0.1015, 0.1505,\n",
       "         0.0967]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(1, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a42135-1dc0-47dc-9c04-19b50c0d4958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T08:26:02.702331Z",
     "iopub.status.busy": "2024-12-22T08:26:02.701997Z",
     "iopub.status.idle": "2024-12-22T08:26:02.721161Z",
     "shell.execute_reply": "2024-12-22T08:26:02.720119Z",
     "shell.execute_reply.started": "2024-12-22T08:26:02.702302Z"
    }
   },
   "source": [
    "#### TensorFlow\n",
    "\n",
    "TensorFlow 2.0 引入了 Keras 库作为其高级 API。无需手动指定每一层的输入维度，但也因此多了一个 `build` 的步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d448638a-99a4-4e18-b41d-3ac9746bc917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:20.167459Z",
     "iopub.status.busy": "2024-12-22T10:43:20.166294Z",
     "iopub.status.idle": "2024-12-22T10:43:20.218103Z",
     "shell.execute_reply": "2024-12-22T10:43:20.217131Z",
     "shell.execute_reply.started": "2024-12-22T10:43:20.167408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Dense name=dense, built=False>, <Dense name=dense_1, built=False>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea48ad4e-c26b-40e0-9351-cb7df9aef0a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:20.219134Z",
     "iopub.status.busy": "2024-12-22T10:43:20.218867Z",
     "iopub.status.idle": "2024-12-22T10:43:20.269105Z",
     "shell.execute_reply": "2024-12-22T10:43:20.268562Z",
     "shell.execute_reply.started": "2024-12-22T10:43:20.219108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[0.05575525, 0.0179697 , 0.07684414, 0.06185716, 0.19958737,\n",
       "        0.14854056, 0.06055942, 0.06959403, 0.15985522, 0.14943717]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 64))\n",
    "model(tf.random.normal(shape=(1, 64)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e167dfbc-c4a6-4956-b027-f76396c90ab5",
   "metadata": {},
   "source": [
    "#### JAX\n",
    "\n",
    "本体不直接提供高层神经网络组件，需要使用第三方库例如 Flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebf4ecb6-8542-47d9-ae8f-98529622e43e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:20.269733Z",
     "iopub.status.busy": "2024-12-22T10:43:20.269584Z",
     "iopub.status.idle": "2024-12-22T10:43:20.447834Z",
     "shell.execute_reply": "2024-12-22T10:43:20.447218Z",
     "shell.execute_reply.started": "2024-12-22T10:43:20.269721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flax import linen as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(128)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(10)(x)\n",
    "        return nn.softmax(x)\n",
    "\n",
    "model = MLP()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d394dc-c3e7-4ce2-8983-9d8731d95574",
   "metadata": {},
   "source": [
    "与 PyTorch 和 TensorFlow 不同，JAX 的随机数 `key` 必须显式地作为参数传入，不存在一个全局的随机数状态。另外，Flax 中模型的参数也是作为参数传入的，模型本身不存储参数信息。这和 JAX 函数式编程的思想是高度一致的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60fdb60e-9875-42f9-a85b-5490439ebbbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:20.449345Z",
     "iopub.status.busy": "2024-12-22T10:43:20.449163Z",
     "iopub.status.idle": "2024-12-22T10:43:20.951063Z",
     "shell.execute_reply": "2024-12-22T10:43:20.950342Z",
     "shell.execute_reply.started": "2024-12-22T10:43:20.449333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.057403  , 0.07946321, 0.06227293, 0.06888593, 0.04725461,\n",
       "        0.12753344, 0.15180823, 0.09623848, 0.1865097 , 0.12263051]],      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "x = jax.random.normal(key, (1, 64))\n",
    "params = model.init(key, x)\n",
    "model.apply(params, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d68975d-825e-42ce-b7af-15b6ab669106",
   "metadata": {},
   "source": [
    "### 数据处理工具"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a675c94-d972-465d-b187-eb73a1dbfc50",
   "metadata": {},
   "source": [
    "#### PyTorch\n",
    "\n",
    "\n",
    "PyTorch 的数据加载和处理模块设计较为简单和直接，提供 `torch.utils.data`，内置 `Dataset` 和 `DataLoader` 可以实现高效的数据预处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17d4b2ab-db4c-417c-af24-d9db0143ab82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:20.951472Z",
     "iopub.status.busy": "2024-12-22T10:43:20.951358Z",
     "iopub.status.idle": "2024-12-22T10:43:20.956999Z",
     "shell.execute_reply": "2024-12-22T10:43:20.956488Z",
     "shell.execute_reply.started": "2024-12-22T10:43:20.951461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[1],\n",
      "        [2]]), tensor([[4],\n",
      "        [5]])]\n",
      "[tensor([[3]]), tensor([[6]])]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "x = torch.tensor([[1], [2], [3]])\n",
    "y = torch.tensor([[4], [5], [6]])\n",
    "dataset = TensorDataset(x, y)\n",
    "dataloader = DataLoader(dataset, batch_size=2)\n",
    "for batch in dataloader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713b4dc2-2ecf-4cf4-b598-9a7f71ff3a0c",
   "metadata": {},
   "source": [
    "#### TensorFlow\n",
    "\n",
    "提供 `tf.data` API，设计较为复杂，但功能强大。提供了丰富的 API 和高级功能，如数据流水线（pipeline）、并行处理、缓存等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd200b8e-8aec-4a2e-a072-8bbb3722ea91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T10:43:20.957536Z",
     "iopub.status.busy": "2024-12-22T10:43:20.957421Z",
     "iopub.status.idle": "2024-12-22T10:43:21.020578Z",
     "shell.execute_reply": "2024-12-22T10:43:21.019783Z",
     "shell.execute_reply.started": "2024-12-22T10:43:20.957525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor([8 1], shape=(2,), dtype=int32)\n",
      "tf.Tensor([0 5], shape=(2,), dtype=int32)\n",
      "tf.Tensor([7 3], shape=(2,), dtype=int32)\n",
      "tf.Tensor([9 2], shape=(2,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-22 18:43:21.017466: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "data = tf.data.Dataset.from_tensor_slices([i for i in range(10)])\n",
    "data = data.shuffle(buffer_size=10).batch(2).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "for batch in data:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167df6f2-1d30-4275-8ef7-04fe53562e54",
   "metadata": {},
   "source": [
    "#### JAX\n",
    "\n",
    "JAX 没有自带的数据处理工具，但可以安装 `tensorflow_datasets` 库，从而获得和 TensorFlow 类似的数据处理体验。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd4810-8d2e-40d0-b8c8-98269300c8f9",
   "metadata": {},
   "source": [
    "## 其他生态\n",
    "\n",
    "### TensorFlow\n",
    "\n",
    "TensorFlow 在工业化部署上有较大优势，提供了包括 TensorFlow Lite（移动端）, TensorFlow.js（浏览器端）等的多种部署方案。\n",
    "\n",
    "此外 TensorFlow Extended (TFX) 提供了完整的端到端生产工作流，TensorBoard 提供了丰富的训练可视化工具。\n",
    "\n",
    "### PyTorch\n",
    "\n",
    "PyTorch 对图像（TorchVision）、音频（TorchAudio）、自然语言（TorchText）都有着强大的支持。\n",
    "\n",
    "此外 TorchServe 也提供了大量模型的服务端部署功能。\n",
    "\n",
    "### JAX\n",
    "\n",
    "JAX 依然是一个比较新的框架，在生态方面处于一定的劣势。但是近年来，越来越多的第三方库除了对 TensorFlow 和 PyTorch 的支持以外，也加入了 JAX 的支持，包括 Keras, Hugging Face 的 Transformers 和 Diffusers 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496707d0-cb12-483b-83a7-97fa69c4b210",
   "metadata": {},
   "source": [
    "## 我该怎么选？\n",
    "\n",
    "\n",
    "- TensorFlow：部署和产业化友好，适合大规模分布式训练和生产环境。\n",
    "- PyTorch：科研和开发模型的首选，强调代码简洁性和动态性。\n",
    "- JAX：与 NumPy 高度一致，高效灵活的数学计算和自动微分。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28573c51-0de3-47aa-8fc2-5bff4223bf11",
   "metadata": {},
   "source": [
    "## 另外，Keras?\n",
    "\n",
    "Keras 严格意义上不是一个独立的神经网络框架，它是依赖于 JAX、PyTorch 或 TensorFlow 作为后端，而它自己扮演的是高级封装的角色。Keras 库最早由谷歌的程序员 Francois Chollet 在 2015 年开发，TensorFlow 问世之后从上古框架 Theano 换到了 TensorFlow。TensorFlow 2.0 出来之后被正式“收编”为 TensorFlow 的官方高级 API。不过后来 Keras 后来又从 TensorFlow 的代码库分离了出来，重新成为了一个独立项目。自从 2023 年 Keras 3.0 发布以来，Keras 正式支持了 JAX、PyTorch 和 TensorFlow 作为后端。\n",
    "\n",
    "所以说 Keras 从定位上讲更像 Flax，我们这里限于篇幅就不展开介绍 Keras 了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a2d00-3f39-4a8d-ac02-61cf0efa0b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
